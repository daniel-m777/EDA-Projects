{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive Bayes Spam Filter\n",
    "\n",
    "In this project we will be building a spam filter using the Multinomial Naive Bayes Algorithm. Our goal will be to aim for a classification accuracy of 80% or higher. The dataset we will be working with contains 5,572 messages classified as *spam* or *ham* and can be accessed at this [link](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).\n",
    "\n",
    "We'll start off by first reading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5572\n",
      "Number of Columns: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sms = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "\n",
    "print('Number of rows: {}\\nNumber of Columns: {}'.format(sms.shape[0], sms.shape[1]))\n",
    "\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of spam: 86.59%\n",
      "Percentage of ham: 13.41%\n"
     ]
    }
   ],
   "source": [
    "# Percentage of spam and ham\n",
    "spam = sms['Label'].value_counts(normalize=True)[0].round(4) * 100\n",
    "ham = sms['Label'].value_counts(normalize=True)[1].round(4) * 100\n",
    "\n",
    "print('Percentage of spam: {}%\\nPercentage of ham: {}%'.format(spam, ham))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Set\n",
    "\n",
    "Now that we have an idea of what we're working with, we can go ahead and split the data into our training set and test set. We'll leave the test set alone for now and just focus on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomize the dataset\n",
    "sms_random = sms.sample(frac=1, random_state=1)\n",
    "\n",
    "# Create test and train sets\n",
    "training_test_index = round(len(sms_random) * 0.2)\n",
    "\n",
    "training_set = sms_random[training_test_index:].reset_index(drop=True)\n",
    "test_set = sms_random[:training_test_index].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "------------\n",
      "Percentage of spam: 86.54104979811575%\n",
      "Percentage of ham: 13.458950201884253%\n",
      "\n",
      "Test Set\n",
      "------------\n",
      "Percentage of spam: 86.80430879712748%\n",
      "Percentage of ham: 13.195691202872531%\n"
     ]
    }
   ],
   "source": [
    "# Percentage of spam and ham - training set\n",
    "spam = training_set['Label'].value_counts(normalize=True)[0] * 100\n",
    "ham = training_set['Label'].value_counts(normalize=True)[1] * 100\n",
    "\n",
    "print('Training Set\\n------------\\nPercentage of spam: {}%\\nPercentage of ham: {}%'.format(spam, ham))\n",
    "\n",
    "# Percentage of spam and ham - test set\n",
    "spam = test_set['Label'].value_counts(normalize=True)[0] * 100\n",
    "ham = test_set['Label'].value_counts(normalize=True)[1] * 100\n",
    "\n",
    "print('\\nTest Set\\n------------\\nPercentage of spam: {}%\\nPercentage of ham: {}%'.format(spam, ham))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lettercase and Punctuation\n",
    "\n",
    "Earlier, we saw that our messages had all kinds or puncuations and spellings, so we are going to go ahead and start cleaning our data up a bit my removing all punctuation and making all our words lowercase for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "training_set['SMS'] = training_set['SMS'].str.replace('\\W', ' ').str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split SMS into word list\n",
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "\n",
    "# Initialize unique vocabulary list\n",
    "vocabulary = []\n",
    "\n",
    "# Add words to vocabulary\n",
    "for message in training_set['SMS']:\n",
    "    for word in message:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "# Remove duplicates\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7753"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dictionary of word counts\n",
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "\n",
    "# Transform into dataframe\n",
    "word_counts_per_sms = pd.DataFrame(word_counts_per_sms)\n",
    "\n",
    "# Merge datasets\n",
    "training_set_clean = pd.concat([training_set, word_counts_per_sms], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yeah, do, don, t, stand, to, close, tho, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[hi, where, are, you, we, re, at, and, they, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[if, you, r, home, then, come, down, within, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[when, re, you, guys, getting, back, g, said, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[tell, my, bad, character, which, u, dnt, lik,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  [yeah, do, don, t, stand, to, close, tho, you,...\n",
       "1   ham  [hi, where, are, you, we, re, at, and, they, r...\n",
       "2   ham  [if, you, r, home, then, come, down, within, 5...\n",
       "3   ham  [when, re, you, guys, getting, back, g, said, ...\n",
       "4   ham  [tell, my, bad, character, which, u, dnt, lik,..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Algorithm Constants\n",
    "\n",
    "According to the Bayes Algorithm, there are some constants that we can go ahead and calculate. We'll go ahead and take care of that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into spam and ham datasets\n",
    "spam_set = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_set = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_set) / len(training_set_clean)\n",
    "p_ham = len(ham_set) / len(training_set_clean)\n",
    "\n",
    "# N_spam\n",
    "n_words_per_spam = spam_set['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam.sum()\n",
    "\n",
    "# N_ham\n",
    "n_words_per_ham = ham_set['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham.sum()\n",
    "\n",
    "# N_vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace Smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Parameters\n",
    "\n",
    "In addition to calculating the constants, we can make things easier for ourselves by also creating dictionaries for the parameters of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "spam_parameters = {unique_word:0 for unique_word in vocabulary}\n",
    "ham_parameters = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# Create\n",
    "for word in vocabulary:\n",
    "    # P(word|spam)\n",
    "    n_word_given_spam = spam_set[word].sum()\n",
    "    p_word_given_spam = ((n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary))\n",
    "    \n",
    "    # P(word|ham)\n",
    "    n_word_given_ham = ham_set[word].sum()\n",
    "    p_word_given_ham = ((n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary))\n",
    "    \n",
    "    # Update parameters\n",
    "    spam_parameters[word] = p_word_given_spam\n",
    "    ham_parameters[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a New Message\n",
    "\n",
    "Now that we've calculated the constants and the required probabilities, we can go ahead and create our function. We'll need to calculate P(Spam|message) and P(Ham|message) as they are not constants and depend on the word we are fixated on. We'll do a quick verification to see if it worked so we can move on to our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    # Clean and split message\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    # Initialize P(Spam|message), P(Ham|message)\n",
    "    p_spam_given_message = p_spam # We include one parameter to make calculations shorter\n",
    "    p_ham_given_message = p_ham # Same applies here\n",
    "    \n",
    "    # Update parameters\n",
    "    for word in message:\n",
    "        if word in spam_parameters:\n",
    "            p_spam_given_message *= spam_parameters[word]\n",
    "        if word in ham_parameters:\n",
    "            p_ham_given_message *= ham_parameters[word]\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.2784957584472927e-25\n",
      "P(Ham|message): 2.5841428475044265e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "# Verify Spam\n",
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 4.774748444294843e-25\n",
      "P(Ham|message): 3.455584370145657e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "# Verify Ham\n",
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Spam Accuracy\n",
    "\n",
    "Now that we have created our algorithm and done a quick verification, it's time to put it to use! First we need to modify our function so that it only returns either 'ham', 'spam', or neither. Afterwards, we can measure the accuracy to see how good our classification was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier(message):\n",
    "    # Clean and split message\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    # Initialize P(Spam|message), P(Ham|message)\n",
    "    p_spam_given_message = p_spam # We include one parameter to make calculations shorter\n",
    "    p_ham_given_message = p_ham # Same applies here\n",
    "    \n",
    "    # Update parameters\n",
    "    for word in message:\n",
    "        if word in spam_parameters:\n",
    "            p_spam_given_message *= spam_parameters[word]\n",
    "        if word in ham_parameters:\n",
    "            p_ham_given_message *= ham_parameters[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'I can\\'t tell!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS Predicted\n",
       "0   ham                       Yep, by the pretty sculpture       ham\n",
       "1   ham      Yes, princess. Are you going to make me moan?       ham\n",
       "2   ham                         Welp apparently he retired       ham\n",
       "3   ham                                            Havent.       ham\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ...       ham"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify Test Set\n",
    "test_set['Predicted'] = test_set['SMS'].apply(test_classifier)\n",
    "\n",
    "# Verify\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.83% \n",
      "Total Correct: 1101 \n",
      "Total Incorrect: 13\n"
     ]
    }
   ],
   "source": [
    "# Initialize accuracy variables\n",
    "correct = 0\n",
    "total = len(test_set)\n",
    "\n",
    "# Measure accuracy\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['Predicted']:\n",
    "        correct += 1\n",
    "accuracy = round((correct/total * 100), 2)\n",
    "                 \n",
    "print('Accuracy: {}%'.format(accuracy),\n",
    "     '\\nTotal Correct:', correct,\n",
    "     '\\nTotal Incorrect:', total - correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only 13 incorrect classifications, it looks like we were able to successfully create a spam filter given that we achieved an accuracy of 98.83%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
